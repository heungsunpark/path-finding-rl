{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-6c927b814203>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6c927b814203>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    __file__ = 'C:\\Users\\ydp2k\\OneDrive\\문서\\GitHub\\path-finding-rl'\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_uppercase\n",
    "from draw_utils import *\n",
    "from pyglet.gl import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# reward\n",
    "move_reward = 0.1\n",
    "obs_reward = 0.1\n",
    "goal_reward = 10\n",
    "print('reward:' , move_reward, obs_reward, goal_reward)\n",
    "\n",
    "__file__ = 'C:\\Users\\ydp2k\\OneDrive\\문서\\GitHub\\path-finding-rl'\n",
    "local_path = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        height : 그리드 높이\n",
    "        width : 그리드 너비 \n",
    "        inds : A ~ Q alphabet list\n",
    "        '''\n",
    "        # Load train data\n",
    "        self.files = pd.read_csv(os.path.join(local_path, \"./data/factory_order_train.csv\"))\n",
    "        self.height = 10\n",
    "        self.width = 9\n",
    "        self.inds = list(ascii_uppercase)[:17]\n",
    "\n",
    "    def set_box(self):\n",
    "        '''\n",
    "        아이템들이 있을 위치를 미리 정해놓고 그 위치 좌표들에 아이템이 들어올 수 있으므로 그리드에 100으로 표시한다.\n",
    "        데이터 파일에서 이번 에피소드 아이템 정보를 받아 가져와야 할 아이템이 있는 좌표만 -100으로 표시한다.\n",
    "        self.local_target에 에이전트가 이번에 방문해야할 좌표들을 저장한다.\n",
    "        따라서 가져와야하는 아이템 좌표와 end point 좌표(처음 시작했던 좌표로 돌아와야하므로)가 들어가게 된다.\n",
    "        '''\n",
    "        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n",
    "\n",
    "        # 물건이 들어있을 수 있는 경우\n",
    "        for box in box_data.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 100\n",
    "\n",
    "        # 물건이 실제 들어있는 경우\n",
    "        order_item = list(set(self.inds) & set(self.items))\n",
    "        order_csv = box_data[box_data['item'].isin(order_item)]\n",
    "\n",
    "        for order_box in order_csv.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = -100\n",
    "            # local target에 가야 할 위치 좌표 넣기\n",
    "            self.local_target.append(\n",
    "                [getattr(order_box, \"row\"),\n",
    "                 getattr(order_box, \"col\")]\n",
    "                )\n",
    "\n",
    "        self.local_target.sort()\n",
    "        self.local_target.append([9,4]) \n",
    "\n",
    "        # 알파벳을 Grid에 넣어서 -> grid에 2Dconv 적용 가능\n",
    "\n",
    "    def set_obstacle(self):\n",
    "        '''\n",
    "        장애물이 있어야하는 위치는 미리 obstacles.csv에 정의되어 있다. 이 좌표들을 0으로 표시한다.\n",
    "        '''\n",
    "        obstacles_data = pd.read_csv(os.path.join(local_path, \"./data/obstacles.csv\"))\n",
    "        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = 0\n",
    "\n",
    "    def reset(self, epi):\n",
    "        '''\n",
    "        reset()은 첫 스텝에서 사용되며 그리드에서 에이전트 위치가 start point에 있게 한다.\n",
    "\n",
    "        :param epi: episode, 에피소드 마다 가져와야 할 아이템 리스트를 불러올 때 사용\n",
    "        :return: 초기셋팅 된 그리드\n",
    "        :rtype: numpy.ndarray\n",
    "        _____________________________________________________________________________________\n",
    "        items : 이번 에피소드에서 가져와야하는 아이템들\n",
    "        terminal_location : 현재 에이전트가 찾아가야하는 목적지\n",
    "        local_target : 한 에피소드에서 찾아가야하는 아이템 좌표, 마지막 엔드 포인트 등의 위치좌표들\n",
    "        actions: visualization을 위해 에이전트 action을 저장하는 리스트\n",
    "        curloc : 현재 위치\n",
    "        '''\n",
    "\n",
    "        # initial episode parameter setting\n",
    "        self.epi = epi\n",
    "        self.items = list(self.files.iloc[self.epi])[0]\n",
    "        self.cumulative_reward = 0\n",
    "        self.terminal_location = None\n",
    "        self.local_target = []\n",
    "        self.actions = []\n",
    "\n",
    "        # initial grid setting\n",
    "        self.grid = np.ones((self.height, self.width), dtype=\"float16\")\n",
    "\n",
    "        # set information about the gridworld\n",
    "        self.set_box()\n",
    "        self.set_obstacle()\n",
    "\n",
    "        # start point를 grid에 표시\n",
    "        self.curloc = [9, 4]\n",
    "        self.grid[int(self.curloc[0])][int(self.curloc[1])] = -5\n",
    "        \n",
    "        self.done = False\n",
    "        \n",
    "        return self.grid\n",
    "\n",
    "    def apply_action(self, action, cur_x, cur_y):\n",
    "        '''\n",
    "        에이전트가 행한 action대로 현 에이전트의 위치좌표를 바꾼다.\n",
    "        action은 discrete하며 4가지 up,down,left,right으로 정의된다.\n",
    "        \n",
    "        :param x: 에이전트의 현재 x 좌표\n",
    "        :param y: 에이전트의 현재 y 좌표\n",
    "        :return: action에 따라 변한 에이전트의 x 좌표, y 좌표\n",
    "        :rtype: int, int\n",
    "        '''\n",
    "        new_x = cur_x\n",
    "        new_y = cur_y\n",
    "        # up\n",
    "        if action == 0:\n",
    "            new_x = cur_x - 1\n",
    "        # down\n",
    "        elif action == 1:\n",
    "            new_x = cur_x + 1\n",
    "        # left\n",
    "        elif action == 2:\n",
    "            new_y = cur_y - 1\n",
    "        # right\n",
    "        else:\n",
    "            new_y = cur_y + 1\n",
    "\n",
    "        return int(new_x), int(new_y)\n",
    "\n",
    "\n",
    "    def get_reward(self, new_x, new_y, out_of_boundary):\n",
    "        '''\n",
    "        get_reward함수는 리워드를 계산하는 함수이며, 상황에 따라 에이전트가 action을 옳게 했는지 판단하는 지표가 된다.\n",
    "\n",
    "        :param new_x: action에 따른 에이전트 새로운 위치좌표 x\n",
    "        :param new_y: action에 따른 에이전트 새로운 위치좌표 y\n",
    "        :param out_of_boundary: 에이전트 위치가 그리드 밖이 되지 않도록 제한\n",
    "        :return: action에 따른 리워드\n",
    "        :rtype: float\n",
    "        '''\n",
    "\n",
    "        # 바깥으로 나가는 경우\n",
    "        if any(out_of_boundary):\n",
    "            reward = obs_reward\n",
    "                       \n",
    "        else:\n",
    "            # 장애물에 부딪히는 경우 \n",
    "            if self.grid[new_x][new_y] == 0:\n",
    "                reward = obs_reward  \n",
    "\n",
    "            # 현재 목표에 도달한 경우\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
    "                reward = goal_reward\n",
    "\n",
    "            # 그냥 움직이는 경우 \n",
    "            else:\n",
    "                reward = move_reward\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        ''' \n",
    "        에이전트의 action에 따라 step을 진행한다.\n",
    "        action에 따라 에이전트 위치를 변환하고, action에 대해 리워드를 받고, 어느 상황에 에피소드가 종료되어야 하는지 등을 판단한다.\n",
    "        에이전트가 endpoint에 도착하면 gif로 에피소드에서 에이전트의 행동이 저장된다.\n",
    "\n",
    "        :param action: 에이전트 행동\n",
    "        :return:\n",
    "            grid, 그리드\n",
    "            reward, 리워드\n",
    "            cumulative_reward, 누적 리워드\n",
    "            done, 종료 여부\n",
    "            goal_ob_reward, goal까지 아이템을 모두 가지고 돌아오는 finish율 계산을 위한 파라미터\n",
    "\n",
    "        :rtype: numpy.ndarray, float, float, bool, bool/str\n",
    "\n",
    "        (Hint : 시작 위치 (9,4)에서 up말고 다른 action은 전부 장애물이므로 action을 고정하는 것이 좋음)\n",
    "        '''\n",
    "\n",
    "        self.terminal_location = self.local_target[0]\n",
    "        cur_x,cur_y = self.curloc\n",
    "        self.actions.append((cur_x, cur_y))\n",
    "\n",
    "        goal_ob_reward = False\n",
    "        \n",
    "        new_x, new_y = self.apply_action(action, cur_x, cur_y)\n",
    "\n",
    "        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]\n",
    "\n",
    "        # 바깥으로 나가는 경우 종료\n",
    "        if any(out_of_boundary):\n",
    "            self.done = True\n",
    "            goal_ob_reward = True\n",
    "        else:\n",
    "            # 장애물에 부딪히는 경우 종료\n",
    "            if self.grid[new_x][new_y] == 0:\n",
    "                self.done = True\n",
    "                goal_ob_reward = True\n",
    "\n",
    "            # 현재 목표에 도달한 경우, 다음 목표설정\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
    "\n",
    "                # end point 일 때\n",
    "                if [new_x, new_y] == [9,4]:\n",
    "                    self.done = True\n",
    "\n",
    "                self.local_target.remove(self.local_target[0])\n",
    "                self.grid[cur_x][cur_y] = 1\n",
    "                self.grid[new_x][new_y] = -5\n",
    "                goal_ob_reward = True\n",
    "                self.curloc = [new_x, new_y]\n",
    "            else:\n",
    "                # 그냥 움직이는 경우 \n",
    "                self.grid[cur_x][cur_y] = 1\n",
    "                self.grid[new_x][new_y] = -5\n",
    "                self.curloc = [new_x,new_y]\n",
    "                \n",
    "        reward = self.get_reward(new_x, new_y, out_of_boundary)\n",
    "        self.cumulative_reward += reward\n",
    "\n",
    "        if self.done == True:\n",
    "            if [new_x, new_y] == [9, 4]:\n",
    "                if self.terminal_location == [9, 4]:\n",
    "                    # 완료되면 GIFS 저장\n",
    "                    goal_ob_reward = 'finish'\n",
    "                    height = 10\n",
    "                    width = 9 \n",
    "                    display = Display(visible=False, size=(width, height))\n",
    "                    display.start()\n",
    "\n",
    "                    start_point = (9, 4)\n",
    "                    unit = 50\n",
    "                    screen_height = height * unit\n",
    "                    screen_width = width * unit\n",
    "                    log_path = \"./logs\"\n",
    "                    data_path = \"./data\"\n",
    "                    render_cls = Render(screen_width, screen_height, unit, start_point, data_path, log_path)\n",
    "                    for idx, new_pos in enumerate(self.actions):\n",
    "                        render_cls.update_movement(new_pos, idx+1)\n",
    "                    \n",
    "                    render_cls.save_gif(self.epi)\n",
    "                    render_cls.viewer.close()\n",
    "                    display.stop()\n",
    "        \n",
    "        return self.grid, reward, self.cumulative_reward, self.done, goal_ob_reward\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sim = Simulator()\n",
    "    files = pd.read_csv(\"./data/factory_order_train.csv\")\n",
    "   \n",
    "    for epi in range(2): # len(files)):\n",
    "        items = list(files.iloc[epi])[0]\n",
    "        done = False\n",
    "        i = 0\n",
    "        obs = sim.reset(epi)\n",
    "        actions = [0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1]\n",
    "\n",
    "        while done == False:\n",
    "            \n",
    "            i += 1\n",
    "            next_obs, reward, cumul ,done, goal_reward = sim.step(actions[i])\n",
    "\n",
    "            obs = next_obs\n",
    "\n",
    "            if (done == True) or (i == (len(actions)-1)):\n",
    "                i =0\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
