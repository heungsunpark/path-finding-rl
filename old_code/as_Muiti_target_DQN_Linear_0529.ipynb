{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3949,
     "status": "ok",
     "timestamp": 1653893085797,
     "user": {
      "displayName": "heungsun 박흥선 park",
      "userId": "16802321133888950576"
     },
     "user_tz": -540
    },
    "id": "lRpfPDrdk9wB",
    "outputId": "a354df2f-1811-4694-dce5-ee5d8e04103a"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "__file__ = 'C:/Users/ydp2k/0_AIFFEL/아이펠톤/BaselineCode/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHFqTLgjMNbJ"
   },
   "source": [
    "## Env\n",
    "- 경로 이동 제한 사항 반영\n",
    "  - del apply_action() 수정\n",
    "- def grid_box(self):  # 그리드 박스 초기화 용도로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1653893089824,
     "user": {
      "displayName": "heungsun 박흥선 park",
      "userId": "16802321133888950576"
     },
     "user_tz": -540
    },
    "id": "tQRnyv3UlBcu",
    "outputId": "aa57c09f-0064-4d65-994b-2b692808edcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -1 -10 10\n",
      "local_path: C:\\Users\\ydp2k\\0_AIFFEL\\아이펠톤\\BaselineCode\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_uppercase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###################################\n",
    "# reward 조정\n",
    "move_reward = -1  # 0.1\n",
    "obs_reward = -10  # 0.1\n",
    "goal_reward = 10  # 10\n",
    "###################################\n",
    "# train / test 모드 지정\n",
    "train_mode = True\n",
    "###################################\n",
    "print('reward:' , move_reward, obs_reward, goal_reward)\n",
    "#__file__ = '/home/ogangza/heung_path_finding/path-finding-rl/data'\n",
    "local_path = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n",
    "print('local_path:', local_path)\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self):\n",
    "        # Load train or test data\n",
    "        if train_mode:  # 훈련 데이타 읽기\n",
    "            self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_train.csv\"))\n",
    "            print('data/factory_order_train.csv used')\n",
    "        else:           # 테스트 데이터 읽기\n",
    "            self.files = pd.read_csv(os.path.join(local_path, \"data/factory_order_test.csv\"))\n",
    "            print('data/factory_order_test.csv used')\n",
    "       \n",
    "        self.height = 10  # 그리드 높이\n",
    "        self.width = 9    #  그리드 너비\n",
    "        self.inds = list(ascii_uppercase)[:17]  # A ~ Q alphabet list\n",
    "\n",
    "    def set_box(self):  # 선반 위치, 목적지 그리드값 설정.  목적지 리스트 생성\n",
    "        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n",
    "        for box in box_data.itertuples(index = True, name ='Pandas'):  # 선반 위치: 그리드값 = 0\n",
    "            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 0\n",
    "        order_item = list(set(self.inds) & set(self.items))\n",
    "        order_csv = box_data[box_data['item'].isin(order_item)]\n",
    "        for order_box in order_csv.itertuples(index = True, name ='Pandas'):  # 목적지: 그리드값 = 2\n",
    "            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = 2\n",
    "            self.local_target.append([getattr(order_box, \"row\"), getattr(order_box, \"col\")])  # 목적지 리스트 생성: local_target\n",
    "        # self.local_target.sort() # 불필요. 인풋 데이터 A, B, C순 정렬되어 있음... 정렬 필요시 코드 바꾸어야 함\n",
    "        self.local_target.append([9,4]) # 목적지 리스트에 최종 목적지(9,4) 추가\n",
    "\n",
    "    def set_obstacle(self):  # 장애물 위치 그리드값 설정 = 0\n",
    "        obstacles_data = pd.read_csv(os.path.join(local_path, \"./data/obstacles.csv\"))\n",
    "        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n",
    "            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = 0\n",
    "\n",
    "    def grid_box(self):  # 그리드 박스 초기화 용도로 정의: 선반, 목적지, 장애물 그리드값 초기화\n",
    "        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n",
    "        for box in box_data.itertuples(index = True, name ='Pandas'):  # 선반 위치: 그리드값 = 0\n",
    "            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 0\n",
    "        order_item = list(set(self.inds) & set(self.items))\n",
    "        order_csv = box_data[box_data['item'].isin(order_item)]\n",
    "        for order_box in order_csv.itertuples(index = True, name ='Pandas'):  # 목적지: 그리드값 = 2\n",
    "            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = 2\n",
    "        self.set_obstacle()  # 장애물 위치 그리드값 설정 = 0\n",
    "        \n",
    "    def reset(self, epi):  # 에피소드 시작시 12개 값 초기화\n",
    "        self.epi = epi                                            #1. 에피소드 번호 받기\n",
    "        self.items = list(self.files.iloc[self.epi])[0]           #2. 에피소드의 목적지 받기: [ 'H', 'L', 'M']\n",
    "        self.cumulative_reward = 0                                #3. 누적 보상값 = 0\n",
    "        self.terminal_location = None                             #4. 최초 목적지\n",
    "        self.local_target = []                                    #5. 목적지 리스트 초기화\n",
    "        self.actions = []                                         #6. 지나온 경로 리스트 초기화\n",
    "        self.grid = np.ones((self.height, self.width), dtype=\"float16\")  #7. 그리드월드 전체 그리드값(1)로 초기화\n",
    "        self.set_box()                                            #8. 선반 위치(0), 목적지(2) 그리드값 설정.  목적지 리스트 생성\n",
    "        self.set_obstacle()                                       #9. 장애물 그리드값(0) 설정\n",
    "        self.curloc = [9, 4]                                      #10. 현재 위치를 출발점으로 세팅\n",
    "        self.grid[int(self.curloc[0])][int(self.curloc[1])] = -1  #11. 현재 위치(출발점) 그리드값(-1) 세팅\n",
    "        self.done = False                                         #12. 경로 찾기 종료 여부 = False\n",
    "        return self.grid\n",
    "\n",
    "    def apply_action(self, action, cur_x, cur_y):  # action에 따른 새 좌표값 반환\n",
    "        new_x = cur_x\n",
    "        new_y = cur_y\n",
    "        if action == 0:          # up\n",
    "            #new_x = cur_x - 1\n",
    "            new_x = self.move_up(cur_x, cur_y, new_x, new_y)\n",
    "        elif action == 1:        # down\n",
    "            #new_x = cur_x + 1\n",
    "            new_x = self.move_down(cur_x, cur_y, new_x, new_y)\n",
    "        elif action == 2:        # left\n",
    "            #new_y = cur_y - 1\n",
    "            new_y = self.move_left(cur_x, cur_y, new_x, new_y)\n",
    "        else:                    # right\n",
    "            #new_y = cur_y + 1\n",
    "            new_y = self.move_right(cur_x, cur_y, new_x, new_y)\n",
    "        return int(new_x), int(new_y)\n",
    "    \n",
    "    # >>> 현재 위치에서 이동이 불가한 위치 추가 (시작) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    def move_up(self, cur_x, cur_y, new_x, new_y):  # action == 0:\n",
    "        if cur_x in [6,5,4,3,2] and cur_y in [0,8]:\n",
    "            pass\n",
    "        else:\n",
    "            new_x = cur_x - 1\n",
    "        return new_x\n",
    "    def move_down(self, cur_x, cur_y, new_x, new_y): # action == 1:\n",
    "        if cur_x in [1,2,3,4,5] and cur_y in [0,8]:\n",
    "            pass\n",
    "        else:\n",
    "            new_x = cur_x + 1\n",
    "        return new_x\n",
    "    def move_left(self, cur_x, cur_y, new_x, new_y): # left elif action == 2:\n",
    "        if cur_y in [1,2,3,4,5,6,7,8] and cur_x == 0:\n",
    "            pass\n",
    "        else:\n",
    "            new_y = cur_y - 1\n",
    "        return new_y\n",
    "    def move_right(self, cur_x, cur_y, new_x, new_y): # right else: action == 3:\n",
    "        if cur_y in [0,1,2,3,4,5,6,7] and cur_x == 0:\n",
    "            pass\n",
    "        else:\n",
    "            new_y = cur_y + 1\n",
    "        return new_y\n",
    "    # >>> 추가 (끝) <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    def get_reward(self, new_x, new_y, out_of_boundary):  # action에 의해 이동시 얻는 보상\n",
    "        if any(out_of_boundary):                          # 바깥으로 나가는 경우\n",
    "            reward = obs_reward                               # -10점\n",
    "        else:\n",
    "            if self.grid[new_x][new_y] == 0:              # 선반이나 장애물에 부딪히는 경우\n",
    "                reward = obs_reward                           # -10점\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:  # 현재 목적지에 도달한 경우\n",
    "                reward = goal_reward                          # 10점\n",
    "            else:                                         # 그냥 움직이는 경우 \n",
    "                reward = move_reward                          # -1점\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):  # action에 따른 이동 실행\n",
    "        self.terminal_location = self.local_target[0]           # 목적지 리스트의 첫 번째 요소를 목적지로 설정\n",
    "        cur_x,cur_y = self.curloc                               # 현재 위치 기억\n",
    "        new_x, new_y = self.apply_action(action, cur_x, cur_y)  # 다음 위치 받기\n",
    "        self.actions.append((new_x, new_y))                     # 새로 도착한 위치를 경로 리스트에 추가\n",
    "        #goal_ob_reward = False  # 사용하지 않음. 사용할 경우, 최종 목적지에 도착한 경우에 True\n",
    "        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]  # 그리드월드 밖으로 나갔는가? OB = True\n",
    "        if any(out_of_boundary):             #1. 바깥으로 나가는 경우 종료하지 않음...\n",
    "            #print('OB')\n",
    "            ######################################################종료 처리할 경우 실행\n",
    "            #self.done = True  # while loop 종료\n",
    "            #self.grid[cur_x][cur_y] = 1   # 현재의 그리드값 초기화(1)\n",
    "            #self.grid_box()  # 선반(0), 목적지(2), 장애물(0) 그리드값 초기화\n",
    "            ######################################################\n",
    "            pass\n",
    "        else:\n",
    "            if self.grid[new_x][new_y] == 0:  #2. 장애물에 부딪히는 경우 종료하지 않음\n",
    "                #print('장애물')\n",
    "                ###################################################종료 처리할 경우 실행\n",
    "                #self.done = True  # while loop 종료\n",
    "                #self.grid[cur_x][cur_y] = 1   # 현재의 그리드값 초기화(1)\n",
    "                #self.grid_box()  # 선반(0), 목적지(2), 장애물(0) 그리드값 초기화\n",
    "                #self.grid[new_x][new_y] = -1  # 현 위치 그리드값(-1)\n",
    "                ###################################################\n",
    "                pass\n",
    "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:  #3. 현재 목적지에 도착한 경우 다음 목적지 설정\n",
    "                #print('목적지 도착')\n",
    "                if [new_x, new_y] == [9, 4]:  #3-1. 최종 목적지에 도착한 경우 종료\n",
    "                    self.done = True  # while loop 종료\n",
    "                    #goal_ob_reward = True  # True = 1 (OB, 장애물 종료 처리 할 경우 self.done=True가 많아지므로 이때 사용)\n",
    "\n",
    "                self.local_target.remove(self.local_target[0])  # 다음 목적지 설정. 최종 목적지에 도착한 경우에는 마지막 요소인 [9,4]를  제거\n",
    "                self.grid[cur_x][cur_y] = 1   # 현재의 그리드값 초기화(1)\n",
    "                self.grid_box()               # 선반(0), 목적지(2), 장애물(0) 그리드값 초기화\n",
    "                self.grid[new_x][new_y] = -1  # 현 위치 그리드값(-1)\n",
    "                self.curloc = [new_x, new_y]  # 새로 도착한 위치를 현재 위치로 변경\n",
    "            else:                             #4. 그냥 움직이는 경우\n",
    "                #print('이동')\n",
    "                self.grid[cur_x][cur_y] = 1   # 현재의 그리드값 초기화(1)\n",
    "                self.grid_box()               # 선반(0), 목적지(2), 장애물(0) 그리드값 초기화\n",
    "                self.grid[new_x][new_y] = -1  # 현 위치 그리드값(-1)\n",
    "                self.curloc = [new_x,new_y]\n",
    "        reward = self.get_reward(new_x, new_y, out_of_boundary)\n",
    "        self.cumulative_reward += reward\n",
    "        return self.grid, reward, self.cumulative_reward, self.done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfJoLw7BM2xw"
   },
   "source": [
    "## Agent\n",
    "- def test_action(self, obs): 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1653893099713,
     "user": {
      "displayName": "heungsun 박흥선 park",
      "userId": "16802321133888950576"
     },
     "user_tz": -540
    },
    "id": "uwgy-OBbk1b4"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class ReplayBuffer():  # 리플레이 버퍼: 경험 저장소\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):  # 리플레이 버퍼(메모리)를 경험(transition)으로 채우기\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):  # memory.sample(batch_size)로 사용\n",
    "        mini_batch = random.sample(self.buffer, n)  # 미니배치 샘플링\n",
    "        '''\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        for transition in mini_batch:  # 경험의 각 요소들을 각각의 미니배치로 구성\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "        '''\n",
    "        state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in mini_batch])\n",
    "        action_batch = torch.Tensor([a for (s1,a,r,s2,d) in mini_batch])\n",
    "        reward_batch = torch.Tensor([r for (s1,a,r,s2,d) in mini_batch])\n",
    "        state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in mini_batch])\n",
    "        done_batch = torch.Tensor([d for (s1,a,r,s2,d) in mini_batch])\n",
    "\n",
    "        return state1_batch, action_batch, reward_batch, state2_batch, done_batch\n",
    "    \n",
    "    def size(self):  # 메모리 크기\n",
    "        return len(self.buffer)\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    ##### Linear 모델 #####\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "\n",
    "        in_size = 90  # input 크기\n",
    "        L1 = 250\n",
    "        L2 = 150\n",
    "        out_size  = 4\n",
    "\n",
    "        self.fc1 = nn.Linear(in_size, L1)\n",
    "        self.fc2 = nn.Linear(L1, L2)\n",
    "        self.fc3 = nn.Linear(L2, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def sample_action(self, obs, epsilon):  # Qnet()을 실행해서 모든 action에 대한 Qval을 구한 후 action 선택\n",
    "        out = self.forward(obs)  # out = Q_value, obs = state = 그리드맵\n",
    "        coin = random.random()  # e-greedy로 action 선택\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,3)\n",
    "        else : \n",
    "            return out.argmax().item()\n",
    "    \n",
    "    def test_action(self, obs):  # Qnet()을 실행해서 모든 action에 대한 Qvalue을 구한 후 action 선택\n",
    "        out = self.forward(obs)  # out = Q_value, obs = state = 그리드맵\n",
    "        return out.argmax().item()\n",
    "\n",
    "def train(q, q_target, memory, optimizer):  # 메모리에 경험이 미니배치 크기 이상 쌓이면 미니배치 훈련 시작\n",
    "    '''\n",
    "    for i in range(10):\n",
    "        s, a, r, cr, s_prime, done_mask, gr = memory.sample(batch_size)\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1,a.to(device))\n",
    "        \n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r.to(device) + gamma * max_q_prime * done_mask.to(device)\n",
    "        \n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    '''\n",
    "    s,a,r,s_prime,done_mask = memory.sample(batch_size)  # 메모리에서 미니배치를 뽑기: batch_size=1600\n",
    "    Q1 = q(s)  # Qnet의 Qvalue\n",
    "    X = Q1.gather(dim=1,index=a.long().unsqueeze(dim=1).to(device)).squeeze() # Qnet의 Qvalue 변환\n",
    "    with torch.no_grad():\n",
    "        Q2 = q_target(s_prime)\n",
    "    Y = r.to(device) + gamma * done_mask.to(device) * torch.max(Q2,dim=1)[0]\n",
    "    loss = F.smooth_l1_loss(X, Y.detach())\n",
    "    #loss = nn.MSELoss(X.to(torch.float32), Y.detach().to(torch.float32))  # 손실함수 변경. target.detach()로 변경\n",
    "    optimizer.zero_grad()  # gradient값 초기화\n",
    "    loss.backward()  # 자동미분\n",
    "    optimizer.step()  # gradient 업데이트\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK35ngIkNM6I"
   },
   "source": [
    "## Main: DQN...\n",
    "  - GPU를 사용할 경우???\n",
    "  - 학습한 모델 불러올 수 있는 코드 추가\n",
    "    - '#' 제거하고 실행시키면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9qFCqbbjf3F",
    "outputId": "12102d0d-445c-45a7-989f-7ee63fd1cd52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor in cpu\n",
      "data/factory_order_train.csv used\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:/Users/ydp2k/0_AIFFEL/아이펠톤/BaselineCode/data\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# action = q.sample_action(state1, epsilon)  # 위 조건을 적용 안 할 경우\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# make Move... action에 따른 이동\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mgridmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcum_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;31m# self.actions.append((new_x, new_y))...새로 도착한 위치를 경로 리스트에 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# 누적 보상 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/ydp2k/0_AIFFEL/아이펠톤/BaselineCode/data\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[1;31m#print('이동')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_y\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m   \u001b[1;31m# 현재의 그리드값 초기화(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m               \u001b[1;31m# 선반(0), 목적지(2), 장애물(0) 그리드값 초기화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_y\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m  \u001b[1;31m# 현 위치 그리드값(-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/ydp2k/0_AIFFEL/아이펠톤/BaselineCode/data\u001b[0m in \u001b[0;36mgrid_box\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgrid_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 그리드 박스 초기화 용도로 정의: 선반, 목적지, 장애물 그리드값 초기화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mbox_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./data/box.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbox_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'Pandas'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 선반 위치: 그리드값 = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"col\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mdata_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;31m# GH10856\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4400\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"isna\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4402\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"isna\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   7264\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"isna\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7266\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7268\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"isna\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    150\u001b[0m         ),\n\u001b[0;32m    151\u001b[0m     ):\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def main(): # DQN... Total Path 학습 모델\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # GPU를 사용할 경우 ???\n",
    "print('tensor in', device)  # GPU 사용 확인\n",
    "PATH = '/content/drive/MyDrive/aiffelthon/data/model_total.pt'\n",
    "tz = pytz.timezone('Asia/Seoul')\n",
    "cur_time = datetime.now(tz)\n",
    "start_time = cur_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "### 중요 Hyperparameters #####################\n",
    "buffer_limit  = 16000      #1. 50000\n",
    "batch_size    = 1600       #2. 32\n",
    "learning_rate = 0.0005     #3. 0.0005\n",
    "sync_freq = 4000           #4. q 네트워크 파라미터를 q_target 네트워크에 복사하는 주기\n",
    "##############################################\n",
    "env = Simulator()  # 데이터셋 읽기. 그리드월드 크기 지정\n",
    "q = Qnet()\n",
    "q.to(device)\n",
    "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "###############################################################\n",
    "## 학습한 모델 불러오기\n",
    "###############################################################\n",
    "#checkpoint = torch.load(PATH)\n",
    "#q.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#epoch = checkpoint['epoch']\n",
    "#loss = checkpoint['loss']\n",
    "#q.train()\n",
    "###############################################################\n",
    "q_target = Qnet()\n",
    "q_target.to(device)\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "### Hyperparameters #####################\n",
    "gamma         = 0.90     #5. 0.98\n",
    "epochs = len(env.files)  #6. 훈련용 데이터 갯수\n",
    "losses = []\n",
    "max_moves = 350          #7.\n",
    "print_interval = 10000    #8.\n",
    "j = 0\n",
    "# epsilon = 0.3            #9. annealing 대신 고정\n",
    "##############################################\n",
    "\n",
    "for n_epi in range(epochs):\n",
    "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) # Linear annealing from 8% to 1%\n",
    "    gridmap = env.reset(n_epi)  # 에피소드 시작시 12개 값 초기화\n",
    "        # self.epi = epi                                            #1. 에피소드 번호 받기\n",
    "        # self.items = list(self.files.iloc[self.epi])[0]           #2. 에피소드의 목적지 받기: [ 'H', 'L', 'M']\n",
    "        # self.cumulative_reward = 0                                #3. 누적 보상값 = 0\n",
    "        # self.terminal_location = None                             #4. 최초 목적지\n",
    "        # self.local_target = []                                    #5. 목적지 리스트 초기화\n",
    "        # self.actions = []                                         #6. 지나온 경로 리스트 초기화\n",
    "        # self.grid = np.ones((self.height, self.width), dtype=\"float16\")  #7. 그리드월드 전체 그리드값(1)로 초기화\n",
    "        # self.set_box()                                            #8. 선반 위치(0), 목적지(2) 그리드값 설정.  목적지 리스트 생성\n",
    "        # self.set_obstacle()                                       #9. 장애물 그리드값(0) 설정\n",
    "        # self.curloc = [9, 4]                                      #10. 현재 위치를 출발점으로 세팅\n",
    "        # self.grid[int(self.curloc[0])][int(self.curloc[1])] = -1  #11. 현재 위치(출발점) 그리드값(-1) 세팅\n",
    "        # self.done = False                                         #12. 경로 찾기 종료 여부 = False\n",
    "        # return self.grid\n",
    "    state1_ = gridmap.reshape(1,90) + np.random.rand(1,90)/100.0  # noise 추가: ReLU activation에서 'dead neurons' 발생 방지\n",
    "    state1 = torch.from_numpy(state1_).float()  # 넘파이 array를 Torch 텐서로 변환\n",
    "    done = False\n",
    "    mov = 0\n",
    "    env.actions.append((9,4))  # 경로 리스트에 [9,4] 추가\n",
    "\n",
    "    while (not done):  # 최종 목적지 [9,4] 도착 또는 max_moves (=350) 초과하면 종료\n",
    "        j += 1\n",
    "        mov += 1\n",
    "        # 상태 state1에서 action 결정\n",
    "        #####################################################################################\n",
    "        if env.curloc == [9,4]:  # 출발점에서는 무조건 위로 올라간다 (action=0)\n",
    "            action = 0\n",
    "        elif env.curloc[0] == 0 and env.curloc[1] in [0,1,2,3,4,5,6,7,8]:  # (0,0)~(0,8)에서는 무조건 아래로\n",
    "            action = 1\n",
    "        elif env.curloc[0] in [2,3,4,5] and env.curloc[1] == 8:  # (2,0)~(5,0)에서는 무조건 왼쪽으로\n",
    "            action = 2\n",
    "        elif env.curloc[0] in [2,3,4,5] and env.curloc[1] == 0:  # (2,0)~(5,0)에서는 무조건 오른쪽으로\n",
    "            action = 3\n",
    "        else:  # 위 경우를 제외하곤 e-greedy로 액션 선택\n",
    "            action = q.sample_action(state1, epsilon)  \n",
    "        #####################################################################################\n",
    "        # action = q.sample_action(state1, epsilon)  # 위 조건을 적용 안 할 경우\n",
    "        # make Move... action에 따른 이동\n",
    "        gridmap, reward, cum_reward, done = env.step(action)\n",
    "            # self.actions.append((new_x, new_y))...새로 도착한 위치를 경로 리스트에 추가\n",
    "            # 누적 보상 계산\n",
    "        state2_ = gridmap.reshape(1,90) + np.random.rand(1,90)/100.0  # noise 추가: ReLU activation에서 'dead neurons' 발생 방지\n",
    "        state2 = torch.from_numpy(state2_).float()  # 넘파이 array를 Torch 텐서로 변환\n",
    "        done_mask = 0.0 if done else 1.0\n",
    "        memory.put((state1, action, reward, state2, done_mask))  # 경험을 메모리에 저장\n",
    "        state1 = state2\n",
    "\n",
    "        if memory.size() > batch_size:  # 메모리에 미니배치 크기 이상 쌓이면... 미니배치 훈련\n",
    "            #print('memory size:', memory.size())\n",
    "            loss = train(q, q_target, memory, optimizer)\n",
    "            if j % print_interval == 0:\n",
    "                print('epiode #:', n_epi, 'loss:', loss)\n",
    "            losses.append(loss)\n",
    "\n",
    "            if j % sync_freq == 0:  # sync_freq마다 q 네트워크 파라미터를 q_target 네트워크로 복사\n",
    "                q_target.load_state_dict(q.state_dict())\n",
    "        if done:\n",
    "            print('종료: done =', done, '... j =', j, ' move =', mov)\n",
    "        if done or mov > max_moves:\n",
    "            mov = 0\n",
    "            done = True\n",
    "\n",
    "    # while loop 종료 ----- 최종 목적지 [9,4] 도착 또는 max_moves (=350) 초과\n",
    "\n",
    "    if n_epi % 1000 == 0 and n_epi != 0:\n",
    "        torch.save({'epoch': n_epi, \n",
    "                    'model_state_dict': q.state_dict(), \n",
    "                    'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'loss': loss, \n",
    "                    }, PATH)\n",
    "        print('▶ 모델 저장됨!!!')\n",
    "'''\n",
    "cur_time = datetime.now(tz)\n",
    "end_time = cur_time.strftime(\"%H:%M:%S\")\n",
    "print ('실행 종료!', 'Start@', start_time, 'End@', end_time)\n",
    "        #cur_time = datetime.now(tz)\n",
    "        #simple_cur_time = cur_time.strftime(\"%H:%M:%S\")\n",
    "        #print('▶ Episode #', iter, 'start time:', simple_cur_time, end='→')\n",
    "'''\n",
    "##print(new_grid_map.reshape(10,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1653880155336,
     "user": {
      "displayName": "heungsun 박흥선 park",
      "userId": "16802321133888950576"
     },
     "user_tz": -540
    },
    "id": "Kq1LVWZdCXIf",
    "outputId": "c6b1a02e-ac09-4baf-bacf-a3d7fbb98c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\",fontsize=22)\n",
    "plt.ylabel(\"Loss\",fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2kNcb0-3j-s"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUyczG0z3nay"
   },
   "source": [
    "## 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "error",
     "timestamp": 1653880156047,
     "user": {
      "displayName": "heungsun 박흥선 park",
      "userId": "16802321133888950576"
     },
     "user_tz": -540
    },
    "id": "bfW9OaPsekYX",
    "outputId": "f4c9632e-fcdf-419a-8769-9d4e60f8c697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/factory_order_test.csv used\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/content/drive/MyDrive/aiffelthon/data\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/aiffelthon/data/model_total.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'len(env.files):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1498\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Qnet:\n\tMissing key(s) in state_dict: \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"fc3.weight\", \"fc3.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". "
     ]
    }
   ],
   "source": [
    "## test 코드 #################################################################################\n",
    "# def test():\n",
    "##############################################################################################\n",
    "train_mode = False  # False: 테스트 모드\n",
    "tz = pytz.timezone('Asia/Seoul')\n",
    "env = Simulator()\n",
    "q = Qnet()\n",
    "PATH = '/content/drive/MyDrive/aiffelthon/data/model_total.pt'\n",
    "q.load_state_dict(torch.load(PATH))\n",
    "q.eval()\n",
    "print('len(env.files):', len(env.files))\n",
    "success_cnt = 0\n",
    "pred_final_path = []\n",
    "\n",
    "# >>>>>>>>> 전체 테스트 데이터에 대한 경로 찾기 시작 <<<<<<<<<<<<<<<<<<<<<\n",
    "for n_epi in range(1225): # range()의 인수로 len(env.files) 사용하면 됨 (=1225)\n",
    "\n",
    "    env.grid = env.reset(n_epi)  # 에피소드 번호에 해당하는 목표물 리스트 env.local_target 생성, 그리드맵 생성\n",
    "    print('▶ Episode #', n_epi,':', list(env.files.iloc[n_epi])[0])\n",
    "    print('   목적지 좌표: ', env.local_target)\n",
    "    #print(\"reset(0) 결과로 받은 최초 그리드맵\")\n",
    "    #print(env.grid)  # ===== 1\n",
    "    pred_local_path = []\n",
    "\n",
    "    # >>>>>>>>> 하나의 에피소드에 대한 대한 최적 경로 찾기 시작 <<<<<<<<<<<<<<<<<<<<<\n",
    "    for n_target in range(len(env.local_target)):\n",
    "    \n",
    "        path_length = 0  # 경로 길이 초기화\n",
    "        env.grid_box()  # 그리드값 초기화\n",
    "        # >>>>>>>>>>>>>> 출발지, 목적지 지정\n",
    "        if n_target == 0:\n",
    "            start_point = [9,4]  # 첫 번째 출발지 지정\n",
    "            print('   출발지', start_point, end=\" → \")\n",
    "        else:\n",
    "            start_point = env.local_target[n_target-1]\n",
    "            print('   출발지', start_point, end=\" → \")\n",
    "        end_point = env.local_target[n_target]  # 목적지 지정\n",
    "        print('목적지', end_point, end=\" >>>>> \")\n",
    "\n",
    "        # >>>>>>>>>>>>>>>>>>>>> 하나의 목적지에 대한 최적 경로 찾기 시작 <<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "        # 출발지, 목적지 좌표 지정\n",
    "        env.x, env.y = start_point                         # 출발지 좌표\n",
    "        env.grid[int(env.x)][int(env.y)] = -5              # 출발지 그리드값 = -5\n",
    "        env.end_x, env.end_y = end_point                   # 목적지 좌표\n",
    "        # 현 위치를 출발지로 reset\n",
    "        env.curloc = start_point\n",
    "        # 목적지 도착 flag (done), 인풋 데이터 (s) 등 초기화\n",
    "        env.done = False\n",
    "        done = False\n",
    "        env.actions = []\n",
    "        env.actions.append(tuple(start_point))\n",
    "        grid_map = env.grid.reshape(-1)          # 그리드 맵\n",
    "        #print(grid_map.reshape(10,9))  # ===== 2\n",
    "        s = np.array(grid_map)\n",
    "\n",
    "        while not done:  # 한 칸씩 이동. 목적지 도착하면 종료\n",
    "            #print('>>>>>>>>>>>> while 시작점... current location:', env.curloc)\n",
    "            #####################################################################################\n",
    "            # (option) 출발점에서는 무조건 위로 올라간다 (action=0)\n",
    "            #if env.curloc == [9,4]:\n",
    "                #a = 0\n",
    "            #elif env.curloc == [0,0] or env.curloc == [0,8]:\n",
    "                #a = 1\n",
    "            #else:\n",
    "                #a = q.sample_action(torch.from_numpy(s).float(), epsilon)  # e-greedy로 액션 선택... 네트워크 결과값으로\n",
    "            #####################################################################################\n",
    "            a = q.test_action(torch.from_numpy(s).float())  # 네트워크 결과값으로 액션 선택\n",
    "            grid, r, cum_reward, done, goal_ob_reward = env.step(a)\n",
    "\n",
    "            # >>>>> 테스트에서 성공 여부 체크에 사용: env.goal_count == len(env.local_target) 이면 성공!\n",
    "            if goal_ob_reward:\n",
    "                env.goal_count += 1  # env.reset()에서 초기화 됨\n",
    "            # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "            new_grid_map = grid.reshape(-1)\n",
    "            #print('액션=', a, '한 칸 이동 결과', 'done=', done)\n",
    "            #print(new_grid_map.reshape(10,9))  # ===== 3\n",
    "            s_prime = np.array(new_grid_map)\n",
    "            s = s_prime\n",
    "            if done:\n",
    "                break  #  while loop 빠져 나가기 \n",
    "            # while loop 종료\n",
    "        \n",
    "        pred_local_path.append(env.actions)  # 최종 경로 구하기 위해 구간 경로를 추가\n",
    "        path_length += len(env.actions)\n",
    "        print('예측 경로:', env.actions)\n",
    "        path_length = 0.0\n",
    "        env.cumulative_reward = 0.0\n",
    "        #print('for loop 종료')\n",
    "        # >>>>>>>>>>>>>>>>>>>>> 하나의 목적지에 대한 최적 경로 찾기 종료 <<<<<<<<<<<<<<<<<<<<<\n",
    "    \n",
    "    # >>>>>>>>> 하나의 에피소드에 대한 대한 최적 경로 찾기 종료 <<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    pred_final_path[n_epi] = pred_local_path  # gif 생성을 위해 최종 경로 저장\n",
    "    ###################################################################################\n",
    "    print('▶ Episode #', n_epi,':', list(env.files.iloc[n_epi])[0])\n",
    "    print('target Grid:', env.local_target)\n",
    "    if env.goal_count >= len(env.local_target):\n",
    "        success_cnt += 1\n",
    "        success_rate = success_cnt /(n_epi+1)\n",
    "        print('성공!!!', env.goal_count, '곳 방문..', '누적 성공률:', success_rate)\n",
    "    else:\n",
    "        print('fail...', len(env.local_target), '중', env.goal_count, '곳 방문..')\n",
    "    ###################################################################################\n",
    "\n",
    "# >>>>>>>>> 전체 훈련 데이터에 대한 최적 경로 찾기 훈련 종료 <<<<<<<<<<<<<<<<<<<<<"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "as_Muiti_target_DQN_Linear_0529.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
